#!/usr/bin/env python3
"""
–í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Excel/CSV/PDF —Ñ–∞–π–ª–æ–≤
–ü–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å, –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤
"""

import os
import pandas as pd
import plotly.graph_objs as go
import plotly.utils
import json
import logging
from flask import Flask, render_template, request, jsonify, send_file
from werkzeug.utils import secure_filename
import tempfile
import io
from datetime import datetime
import numpy as np
import pdfplumber
from dotenv import load_dotenv
from yandex_gpt_module import create_yandex_analyzer
from gigachat_module import create_gigachat_analyzer
from pdf_generator import create_pdf_report

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–Ω–∏–µ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('FLASK_SECRET_KEY', 'your-secret-key-here')
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024  # 200MB max file size
app.config['MAX_CONTENT_PATH'] = 200 * 1024 * 1024  # 200MB max content path

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è GitHub Pages
from flask_cors import CORS
CORS(app, origins=['https://yourusername.github.io', 'http://localhost:5000'])

# –ü–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'csv', 'pdf'}

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

def allowed_file(filename):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Ä–∞–∑—Ä–µ—à–µ–Ω –ª–∏ —Ç–∏–ø —Ñ–∞–π–ª–∞"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def convert_dataframe_to_json_safe(df):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç DataFrame –≤ JSON-–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    df_clean = df.copy()
    
    for column in df_clean.columns:
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy —Ç–∏–ø—ã –≤ Python —Ç–∏–ø—ã
            if df_clean[column].dtype == 'int64':
                df_clean[column] = df_clean[column].astype('int')
            elif df_clean[column].dtype == 'float64':
                df_clean[column] = df_clean[column].astype('float')
            elif df_clean[column].dtype == 'bool':
                df_clean[column] = df_clean[column].astype('bool')
            elif 'datetime' in str(df_clean[column].dtype):
                df_clean[column] = df_clean[column].astype('str')
            elif df_clean[column].dtype == 'object':
                # –î–ª—è object —Ç–∏–ø–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                sample_values = df_clean[column].dropna().head(5)
                if len(sample_values) > 0:
                    # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–∞
                    try:
                        pd.to_numeric(sample_values.iloc[0])
                        df_clean[column] = pd.to_numeric(df_clean[column], errors='coerce').astype('float')
                    except:
                        # –ï—Å–ª–∏ –Ω–µ —á–∏—Å–ª–æ, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                        df_clean[column] = df_clean[column].astype('str')
                else:
                    df_clean[column] = df_clean[column].astype('str')
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞ {column}: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫–∏
            try:
                df_clean[column] = df_clean[column].astype('str')
            except:
                # –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                df_clean[column] = ''
    
    # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ None
    df_clean = df_clean.where(pd.notnull(df_clean), None)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ numpy —Ç–∏–ø—ã –∏ Timestamp –Ω–∞ Python —Ç–∏–ø—ã
    for column in df_clean.columns:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º .loc –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è chained assignment
            for i in range(len(df_clean[column])):
                value = df_clean[column].iloc[i]
                if hasattr(value, 'item'):  # numpy scalar
                    df_clean.loc[df_clean.index[i], column] = value.item()
                elif isinstance(value, (np.integer, np.floating)):
                    df_clean.loc[df_clean.index[i], column] = value.item()
                elif hasattr(value, 'strftime'):  # Timestamp –∏–ª–∏ datetime –æ–±—ä–µ–∫—Ç
                    df_clean.loc[df_clean.index[i], column] = str(value)
                elif isinstance(value, pd.Timestamp):  # pandas Timestamp
                    df_clean.loc[df_clean.index[i], column] = str(value)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—Ç–æ–ª–±—Ü–∞ {column}: {e}")
    
    return df_clean

def detect_data_types(df):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame"""
    data_types = {}
    
    for column in df.columns:
        # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
        if df[column].dtype in ['int64', 'float64']:
            data_types[column] = 'numeric'
        elif df[column].dtype == 'object':
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –¥–∞—Ç–æ–π
            try:
                # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                sample_values = df[column].dropna().head(3)
                if len(sample_values) > 0:
                    # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É
                    pd.to_datetime(sample_values.iloc[0])
                    data_types[column] = 'datetime'
                else:
                    data_types[column] = 'text'
            except:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
                try:
                    sample_values = df[column].dropna().head(3)
                    if len(sample_values) > 0:
                        pd.to_numeric(sample_values.iloc[0])
                        data_types[column] = 'numeric'
                    else:
                        data_types[column] = 'text'
                except:
                    data_types[column] = 'text'
        else:
            data_types[column] = 'text'
    
    return data_types

def get_basic_analytics(df):
    """–ü–æ–ª—É—á–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ DataFrame"""
    analytics = {
        'total_rows': int(len(df)),
        'total_columns': int(len(df.columns)),
        'columns_info': {},
        'summary_stats': {}
    }
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    numeric_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
    text_columns = [col for col in df.columns if df[col].dtype == 'object']
    
    analytics['summary_stats'] = {
        'numeric_columns': len(numeric_columns),
        'text_columns': len(text_columns),
        'total_missing_values': int(df.isnull().sum().sum()),
        'completeness_percentage': round((1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100, 2)
    }
    
    for column in df.columns:
        col_info = {
            'dtype': str(df[column].dtype),
            'non_null_count': int(df[column].count()),
            'null_count': int(df[column].isnull().sum()),
            'unique_count': int(df[column].nunique()),
            'completeness': round((df[column].count() / len(df)) * 100, 2)
        }
        
        # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if df[column].dtype in ['int64', 'float64']:
            try:
                col_info.update({
                    'sum': float(df[column].sum()) if not df[column].isnull().all() else 0.0,
                    'mean': float(df[column].mean()) if not df[column].isnull().all() else 0.0,
                    'min': float(df[column].min()) if not df[column].isnull().all() else 0.0,
                    'max': float(df[column].max()) if not df[column].isnull().all() else 0.0,
                    'median': float(df[column].median()) if not df[column].isnull().all() else 0.0,
                    'std': float(df[column].std()) if not df[column].isnull().all() else 0.0
                })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Å—Ç–æ–ª–±—Ü–∞ {column}: {e}")
                col_info.update({
                    'sum': 0.0,
                    'mean': 0.0,
                    'min': 0.0,
                    'max': 0.0,
                    'median': 0.0,
                    'std': 0.0
                })
        
        # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        elif df[column].dtype == 'object':
            try:
                top_values = df[column].value_counts().head(5)
                col_info['top_values'] = {
                    str(k): int(v) for k, v in top_values.items()
                }
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                col_info['unique_values_count'] = int(df[column].nunique())
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ {column}: {e}")
                col_info['top_values'] = {}
                col_info['unique_values_count'] = 0
        
        analytics['columns_info'][column] = col_info
    
    return analytics

def create_charts(df, data_types):
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏–∞–≥—Ä–∞–º–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    charts = []
    
    # –ò—â–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è bar chart
    numeric_columns = [col for col, dtype in data_types.items() if dtype == 'numeric']
    text_columns = [col for col, dtype in data_types.items() if dtype == 'text']
    datetime_columns = [col for col, dtype in data_types.items() if dtype == 'datetime']
    
    # 1. Bar chart: –¢–æ–ø –º–∞—Ä–æ–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–¥–∞–∂
    if 'make' in text_columns and len(numeric_columns) > 0:
        try:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∞—Ä–∫–∞–º –∏ —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            grouped_data = df.groupby('make').size().head(10)  # –¢–æ–ø 10 –º–∞—Ä–æ–∫
            
            if len(grouped_data) > 0:
                x_values = [str(x) for x in grouped_data.index]
                y_values = [int(y) for y in grouped_data.values]
                
                fig = go.Figure(data=[
                    go.Bar(
                        x=x_values,
                        y=y_values,
                        marker_color='#1e3a8a',
                        text=y_values,
                        textposition='auto'
                    )
                ])
                
                fig.update_layout(
                    title='–¢–æ–ø 10 –º–∞—Ä–æ–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–¥–∞–∂',
                    xaxis_title='–ú–∞—Ä–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è',
                    yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–∂',
                    font=dict(family="Georgia, serif"),
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    height=400
                )
                
                charts.append({
                    'type': 'bar',
                    'title': '–¢–æ–ø 10 –º–∞—Ä–æ–∫ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–¥–∞–∂',
                    'data': json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)
                })
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è bar chart –º–∞—Ä–æ–∫: {e}")
    
    # 2. Line chart: –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –≥–æ–¥–∞–º
    if 'year' in numeric_columns and 'sellingprice' in numeric_columns:
        try:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≥–æ–¥–∞–º –∏ —Å—á–∏—Ç–∞–µ–º —Å—É–º–º—É –ø—Ä–æ–¥–∞–∂
            grouped_data = df.groupby('year')['sellingprice'].sum().sort_index()
            
            if len(grouped_data) > 1:
                x_values = [str(x) for x in grouped_data.index]
                y_values = [float(y) for y in grouped_data.values]
                
                fig = go.Figure(data=[
                    go.Scatter(
                        x=x_values,
                        y=y_values,
                        mode='lines+markers',
                        line=dict(color='#1e3a8a', width=3),
                        marker=dict(size=8, color='#3b82f6'),
                        fill='tonexty'
                    )
                ])
                
                fig.update_layout(
                    title='–û–±—â–∞—è —Å—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –≥–æ–¥–∞–º',
                    xaxis_title='–ì–æ–¥',
                    yaxis_title='–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ ($)',
                    font=dict(family="Georgia, serif"),
                    plot_bgcolor='white',
                    paper_bgcolor='white',
                    height=400
                )
                
                charts.append({
                    'type': 'line',
                    'title': '–û–±—â–∞—è —Å—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –≥–æ–¥–∞–º',
                    'data': json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)
                })
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è line chart –ø–æ –≥–æ–¥–∞–º: {e}")
    
    return charts

def get_available_categories(df, data_types):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º"""
    categories = {
        'text_columns': [col for col, dtype in data_types.items() if dtype == 'text'],
        'numeric_columns': [col for col, dtype in data_types.items() if dtype == 'numeric'],
        'datetime_columns': [col for col, dtype in data_types.items() if dtype == 'datetime']
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for col in categories['text_columns']:
        try:
            unique_count = df[col].nunique()
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON-—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            sample_values = df[col].value_counts().head(5)
            sample_dict = {}
            for key, value in sample_values.items():
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–ª—é—á –≤ —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –±–∞–∑–æ–≤—ã–π —Ç–∏–ø
                if hasattr(key, 'strftime'):  # Timestamp –∏–ª–∏ datetime
                    sample_dict[str(key)] = int(value)
                elif isinstance(key, pd.Timestamp):  # pandas Timestamp
                    sample_dict[str(key)] = int(value)
                else:
                    sample_dict[str(key)] = int(value)
            
            categories[col] = {
                'type': 'text',
                'unique_count': int(unique_count),
                'sample_values': sample_dict
            }
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {col}: {e}")
            categories[col] = {'type': 'text', 'unique_count': 0, 'sample_values': {}}
    
    return categories

def extract_table_from_pdf(filepath):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤—É—é —Ç–∞–±–ª–∏—Ü—É –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    try:
        with pdfplumber.open(filepath) as pdf:
            if len(pdf.pages) == 0:
                raise ValueError("PDF —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            first_page = pdf.pages[0]
            tables = first_page.extract_tables()
            
            if not tables:
                raise ValueError("–ù–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ PDF –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü")
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            table = tables[0]
            
            if not table or len(table) == 0:
                raise ValueError("–ü–µ—Ä–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤ PDF –ø—É—Å—Ç–∞")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ DataFrame
            # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if len(table) < 2:
                raise ValueError("–¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–∞–∫ –º–∏–Ω–∏–º—É–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö")
            
            headers = table[0]
            data_rows = table[1:]
            
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame(data_rows, columns=headers)
            
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            df = df.dropna(how='all')  # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            df = df.dropna(axis=1, how='all')  # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            
            # –ó–∞–º–µ–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ None
            df = df.where(pd.notnull(df), None)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            for column in df.columns:
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
                    df[column] = pd.to_numeric(df[column], errors='coerce')
                except:
                    pass
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É –¥–ª—è –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É
                    df[column] = pd.to_datetime(df[column], errors='coerce')
                except:
                    pass
            
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –∏–∑ PDF: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
            logger.info(f"–°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
            
            return df
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –∏–∑ PDF: {e}")
        raise e

# –ú–∞—Ä—à—Ä—É—Ç—ã Flask
@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ Excel/CSV/PDF —Ñ–∞–π–ª–∞"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –†–∞–∑—Ä–µ—à–µ–Ω—ã: xlsx, xls, csv, pdf'}), 400
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        try:
            if filename.endswith('.pdf'):
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                df = extract_table_from_pdf(filepath)
            elif filename.endswith('.csv'):
                # –î–ª—è CSV —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                file_size = os.path.getsize(filepath)
                if file_size > 10 * 1024 * 1024:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–µ 10MB
                    # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10000 —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    df = pd.read_csv(filepath, encoding='utf-8', nrows=10000)
                    logger.info(f"–§–∞–π–ª –±–æ–ª—å—à–æ–π ({file_size / 1024 / 1024:.1f}MB), —á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 10000 —Å—Ç—Ä–æ–∫")
                else:
                    df = pd.read_csv(filepath, encoding='utf-8')
            else:
                # –î–ª—è Excel —Ñ–∞–π–ª–æ–≤
                file_size = os.path.getsize(filepath)
                if file_size > 10 * 1024 * 1024:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–µ 10MB
                    # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10000 —Å—Ç—Ä–æ–∫
                    df = pd.read_excel(filepath, nrows=10000)
                    logger.info(f"–§–∞–π–ª –±–æ–ª—å—à–æ–π ({file_size / 1024 / 1024:.1f}MB), —á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 10000 —Å—Ç—Ä–æ–∫")
                else:
                    df = pd.read_excel(filepath)
        except Exception as e:
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è CSV
            if filename.endswith('.csv'):
                try:
                    file_size = os.path.getsize(filepath)
                    if file_size > 10 * 1024 * 1024:
                        df = pd.read_csv(filepath, encoding='cp1251', nrows=10000)
                    else:
                        df = pd.read_csv(filepath, encoding='cp1251')
                except:
                    try:
                        file_size = os.path.getsize(filepath)
                        if file_size > 10 * 1024 * 1024:
                            df = pd.read_csv(filepath, encoding='latin-1', nrows=10000)
                        else:
                            df = pd.read_csv(filepath, encoding='latin-1')
                    except:
                        raise e
            else:
                raise e
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = df.dropna(how='all')  # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        df = df.dropna(axis=1, how='all')  # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        
        # –ó–∞–º–µ–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ None –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        df = df.where(pd.notnull(df), None)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df = df.replace(['', ' ', '  ', '   '], None)  # –ó–∞–º–µ–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ None
        df = df.replace(['nan', 'NaN', 'NAN'], None)  # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ 'nan' –Ω–∞ None
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame: {dict(df.dtypes)}")
        logger.info(f"–†–∞–∑–º–µ—Ä DataFrame: {df.shape}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        data_types = detect_data_types(df)
        
        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        analytics = get_basic_analytics(df)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—ã
        charts = create_charts(df, data_types)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º
        categories = get_available_categories(df, data_types)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        df_display = df.head(100)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ JSON-–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        df_display_clean = convert_dataframe_to_json_safe(df_display)
        data_json = df_display_clean.to_json(orient='records', date_format='iso')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(filepath)
        file_size_mb = file_size / (1024 * 1024)
        
        return jsonify({
            'success': True,
            'filename': filename,
            'data': json.loads(data_json),
            'columns': list(df.columns),
            'total_rows': len(df),
            'data_types': data_types,
            'analytics': analytics,
            'charts': charts,
            'categories': categories,
            'has_more_data': len(df) > 100,
            'file_size_mb': round(file_size_mb, 2),
            'is_large_file': file_size > 10 * 1024 * 1024
        })
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}'}), 500

@app.route('/load_more', methods=['POST'])
def load_more_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        data = request.get_json()
        filename = data.get('filename')
        start_row = data.get('start_row', 0)
        rows_count = data.get('rows_count', 100)
        
        if not filename:
            return jsonify({'error': '–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'}), 400
        
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        if not os.path.exists(filepath):
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        if filename.endswith('.pdf'):
            df = extract_table_from_pdf(filepath)
        elif filename.endswith('.csv'):
            df = pd.read_csv(filepath, encoding='utf-8')
        else:
            df = pd.read_excel(filepath)
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = df.dropna(how='all')
        df = df.dropna(axis=1, how='all')
        
        # –ó–∞–º–µ–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ None –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        df = df.where(pd.notnull(df), None)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ load_more: {dict(df.dtypes)}")
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–æ–∫
        end_row = min(start_row + rows_count, len(df))
        df_slice = df.iloc[start_row:end_row]
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON-–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        df_slice_clean = convert_dataframe_to_json_safe(df_slice)
        data_json = df_slice_clean.to_json(orient='records', date_format='iso')
        
        return jsonify({
            'success': True,
            'data': json.loads(data_json),
            'start_row': start_row,
            'end_row': end_row,
            'has_more_data': end_row < len(df)
        })
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}'}), 500

@app.route('/create_chart', methods=['POST'])
def create_custom_chart():
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏–∞–≥—Ä–∞–º–º—É –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    try:
        data = request.get_json()
        filename = data.get('filename')
        category = data.get('category')
        chart_type = data.get('chart_type', 'bar')
        
        if not filename or not category:
            return jsonify({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã'}), 400
        
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        if not os.path.exists(filepath):
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        if filename.endswith('.pdf'):
            df = extract_table_from_pdf(filepath)
        elif filename.endswith('.csv'):
            df = pd.read_csv(filepath, encoding='utf-8')
        else:
            df = pd.read_excel(filepath)
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = df.dropna(how='all')
        df = df.dropna(axis=1, how='all')
        df = df.where(pd.notnull(df), None)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        data_types = detect_data_types(df)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥—Ä–∞–º–º—É
        if chart_type == 'bar':
            # Bar chart: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            try:
                grouped_data = df.groupby(category).size().head(15)  # –¢–æ–ø 15
                
                if len(grouped_data) > 0:
                    x_values = [str(x) for x in grouped_data.index]
                    y_values = [int(y) for y in grouped_data.values]
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            x=x_values,
                            y=y_values,
                            marker_color='#1e3a8a',
                            text=y_values,
                            textposition='auto'
                        )
                    ])
                    
                    fig.update_layout(
                        title=f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ {category}',
                        xaxis_title=category,
                        yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
                        font=dict(family="Georgia, serif"),
                        plot_bgcolor='white',
                        paper_bgcolor='white',
                        height=400
                    )
                    
                    chart_data = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)
                    
                    return jsonify({
                        'success': True,
                        'chart': {
                            'type': 'bar',
                            'title': f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ {category}',
                            'data': chart_data
                        }
                    })
                else:
                    return jsonify({'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã'}), 400
                    
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è bar chart: {e}")
                return jsonify({'error': f'–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã: {str(e)}'}), 500
        
        elif chart_type == 'line':
            # Line chart: –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ (–µ—Å–ª–∏ –µ—Å—Ç—å —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã)
            numeric_columns = [col for col, dtype in data_types.items() if dtype == 'numeric']
            if len(numeric_columns) > 0:
                try:
                    value_col = numeric_columns[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü
                    grouped_data = df.groupby(category)[value_col].sum().sort_index()
                    
                    if len(grouped_data) > 1:
                        x_values = [str(x) for x in grouped_data.index]
                        y_values = [float(y) for y in grouped_data.values]
                        
                        fig = go.Figure(data=[
                            go.Scatter(
                                x=x_values,
                                y=y_values,
                                mode='lines+markers',
                                line=dict(color='#1e3a8a', width=3),
                                marker=dict(size=8, color='#3b82f6')
                            )
                        ])
                        
                        fig.update_layout(
                            title=f'{value_col} –ø–æ {category}',
                            xaxis_title=category,
                            yaxis_title=value_col,
                            font=dict(family="Georgia, serif"),
                            plot_bgcolor='white',
                            paper_bgcolor='white',
                            height=400
                        )
                        
                        chart_data = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)
                        
                        return jsonify({
                            'success': True,
                            'chart': {
                                'type': 'line',
                                'title': f'{value_col} –ø–æ {category}',
                                'data': chart_data
                            }
                        })
                    else:
                        return jsonify({'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏–Ω–µ–π–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã'}), 400
                        
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è line chart: {e}")
                    return jsonify({'error': f'–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã: {str(e)}'}), 500
            else:
                return jsonify({'error': '–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã'}), 400
        
        else:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–∏–∞–≥—Ä–∞–º–º—ã'}), 400
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã: {str(e)}'}), 500

@app.route('/yandex_analysis', methods=['POST'])
def yandex_analysis():
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é –Ø–Ω–¥–µ–∫—Å.GPT"""
    try:
        print("ü§ñ [YANDEX] –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å.GPT")
        data = request.get_json()
        filename = data.get('filename')
        
        print(f"üìÑ [YANDEX] –ó–∞–ø—Ä–æ—à–µ–Ω —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {filename}")
        
        if not filename:
            print("‚ùå [YANDEX] –û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–º—è —Ñ–∞–π–ª–∞")
            return jsonify({'error': '–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if not os.path.exists(filepath):
            print(f"‚ùå [YANDEX] –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {filepath}")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
        
        print(f"‚úÖ [YANDEX] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {filepath}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤—ã—Ö 15 —Å—Ç—Ä–æ–∫
        try:
            if filename.endswith('.pdf'):
                print("üìä [YANDEX] –ß–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª...")
                df = extract_table_from_pdf(filepath)
            elif filename.endswith('.csv'):
                print("üìä [YANDEX] –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª...")
                df = pd.read_csv(filepath, encoding='utf-8')
            else:
                print("üìä [YANDEX] –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª...")
                df = pd.read_excel(filepath)
        except Exception as e:
            print(f"‚ö†Ô∏è [YANDEX] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å UTF-8, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è CSV
            if filename.endswith('.csv'):
                try:
                    print("üìä [YANDEX] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É cp1251...")
                    df = pd.read_csv(filepath, encoding='cp1251')
                except:
                    try:
                        print("üìä [YANDEX] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É latin-1...")
                        df = pd.read_csv(filepath, encoding='latin-1')
                    except:
                        print(f"‚ùå [YANDEX] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                        return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
            else:
                print(f"‚ùå [YANDEX] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
        
        print(f"üìà [YANDEX] –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("üßπ [YANDEX] –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        df = df.dropna(how='all')
        df = df.dropna(axis=1, how='all')
        df = df.where(pd.notnull(df), None)
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 15 —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        df_sample = df.head(15)
        print(f"üìã [YANDEX] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(df_sample)} —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON-–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        df_sample_clean = convert_dataframe_to_json_safe(df_sample)
        table_data = df_sample_clean.to_dict('records')
        print(f"üîÑ [YANDEX] –î–∞–Ω–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ JSON —Ñ–æ—Ä–º–∞—Ç")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ø–Ω–¥–µ–∫—Å.GPT
        print("üîß [YANDEX] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ø–Ω–¥–µ–∫—Å.GPT...")
        analyzer = create_yandex_analyzer()
        if not analyzer:
            print("‚ùå [YANDEX] –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
            return jsonify({
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ø–Ω–¥–µ–∫—Å.GPT. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env —Ñ–∞–π–ª–µ.'
            }), 500
        
        print("‚úÖ [YANDEX] –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ø–Ω–¥–µ–∫—Å.GPT –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        print("üöÄ [YANDEX] –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å.GPT...")
        logger.info(f"–ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {filename} —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å.GPT")
        analysis_result = analyzer.analyze_table_data(table_data, filename)
        
        if analysis_result['success']:
            analysis_length = len(analysis_result['analysis'])
            print(f"‚úÖ [YANDEX] –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìä [YANDEX] –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {analysis_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"ü§ñ [YANDEX] –ú–æ–¥–µ–ª—å: {analysis_result['model']}")
            return jsonify({
                'success': True,
                'analysis': {
                    'status': 'completed',
                    'message': '–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                    'content': analysis_result['analysis'],
                    'model': analysis_result['model'],
                    'filename': analysis_result['filename']
                }
            })
        else:
            print(f"‚ùå [YANDEX] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {analysis_result['error']}")
            return jsonify({
                'success': False,
                'error': analysis_result['error']
            }), 500
        
    except Exception as e:
        print(f"‚ùå [YANDEX] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        print(f"üîç [YANDEX] –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
        logger.error(f"–û—à–∏–±–∫–∞ Yandex –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'}), 500

@app.route('/gigachat_analysis', methods=['POST'])
def gigachat_analysis():
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é GigaChat"""
    try:
        print("ü§ñ [GIGACHAT] –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ GigaChat")
        data = request.get_json()
        filename = data.get('filename')
        
        print(f"üìÑ [GIGACHAT] –ó–∞–ø—Ä–æ—à–µ–Ω —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {filename}")
        
        if not filename:
            print("‚ùå [GIGACHAT] –û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–º—è —Ñ–∞–π–ª–∞")
            return jsonify({'error': '–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if not os.path.exists(filepath):
            print(f"‚ùå [GIGACHAT] –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {filepath}")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
        
        print(f"‚úÖ [GIGACHAT] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {filepath}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤—ã—Ö 15 —Å—Ç—Ä–æ–∫
        try:
            if filename.endswith('.pdf'):
                print("üìä [GIGACHAT] –ß–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª...")
                df = extract_table_from_pdf(filepath)
            elif filename.endswith('.csv'):
                print("üìä [GIGACHAT] –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª...")
                df = pd.read_csv(filepath, encoding='utf-8')
            else:
                print("üìä [GIGACHAT] –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª...")
                df = pd.read_excel(filepath)
        except Exception as e:
            print(f"‚ö†Ô∏è [GIGACHAT] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å UTF-8, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è CSV
            if filename.endswith('.csv'):
                try:
                    print("üìä [GIGACHAT] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É cp1251...")
                    df = pd.read_csv(filepath, encoding='cp1251')
                except:
                    try:
                        print("üìä [GIGACHAT] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É latin-1...")
                        df = pd.read_csv(filepath, encoding='latin-1')
                    except:
                        print(f"‚ùå [GIGACHAT] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                        return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
            else:
                print(f"‚ùå [GIGACHAT] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
        
        print(f"üìà [GIGACHAT] –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("üßπ [GIGACHAT] –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        df = df.dropna(how='all')
        df = df.dropna(axis=1, how='all')
        df = df.where(pd.notnull(df), None)
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 15 —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        df_sample = df.head(15)
        print(f"üìã [GIGACHAT] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(df_sample)} —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON-–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        df_sample_clean = convert_dataframe_to_json_safe(df_sample)
        table_data = df_sample_clean.to_dict('records')
        print(f"üîÑ [GIGACHAT] –î–∞–Ω–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ JSON —Ñ–æ—Ä–º–∞—Ç")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä GigaChat
        print("üîß [GIGACHAT] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä GigaChat...")
        analyzer = create_gigachat_analyzer()
        if not analyzer:
            print("‚ùå [GIGACHAT] –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
            return jsonify({
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä GigaChat. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env —Ñ–∞–π–ª–µ.'
            }), 500
        
        print("‚úÖ [GIGACHAT] –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä GigaChat –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        print("üöÄ [GIGACHAT] –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ GigaChat...")
        logger.info(f"–ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {filename} —á–µ—Ä–µ–∑ GigaChat")
        analysis_result = analyzer.analyze_table_data(table_data, filename)
        
        if analysis_result['success']:
            analysis_length = len(analysis_result['analysis'])
            print(f"‚úÖ [GIGACHAT] –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìä [GIGACHAT] –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {analysis_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"ü§ñ [GIGACHAT] –ú–æ–¥–µ–ª—å: {analysis_result['model']}")
            return jsonify({
                'success': True,
                'analysis': {
                    'status': 'completed',
                    'message': '–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                    'content': analysis_result['analysis'],
                    'model': analysis_result['model'],
                    'filename': analysis_result['filename']
                }
            })
        else:
            print(f"‚ùå [GIGACHAT] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {analysis_result['error']}")
            return jsonify({
                'success': False,
                'error': analysis_result['error']
            }), 500
        
    except Exception as e:
        print(f"‚ùå [GIGACHAT] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        print(f"üîç [GIGACHAT] –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
        logger.error(f"–û—à–∏–±–∫–∞ GigaChat –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'}), 500

@app.route('/generate_pdf', methods=['POST'])
def generate_pdf():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF –æ—Ç—á–µ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"""
    try:
        print("üîÑ [PDF] –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF –æ—Ç—á—ë—Ç–∞")
        data = request.get_json()
        filename = data.get('filename')
        yandex_analysis = data.get('yandex_analysis', '')
        gigachat_analysis = data.get('gigachat_analysis', '')
        
        print(f"üìÑ [PDF] –ó–∞–ø—Ä–æ—à–µ–Ω —Ñ–∞–π–ª: {filename}")
        print(f"ü§ñ [PDF] –Ø–Ω–¥–µ–∫—Å.GPT –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω: {'–î–∞' if yandex_analysis else '–ù–µ—Ç'}")
        print(f"ü§ñ [PDF] GigaChat –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω: {'–î–∞' if gigachat_analysis else '–ù–µ—Ç'}")
        
        if not filename:
            print("‚ùå [PDF] –û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–º—è —Ñ–∞–π–ª–∞")
            return jsonify({'error': '–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'}), 400
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        if not os.path.exists(filepath):
            print(f"‚ùå [PDF] –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {filepath}")
            return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
        
        print(f"‚úÖ [PDF] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {filepath}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        try:
            if filename.endswith('.pdf'):
                print("üìä [PDF] –ß–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª...")
                df = extract_table_from_pdf(filepath)
            elif filename.endswith('.csv'):
                print("üìä [PDF] –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª...")
                df = pd.read_csv(filepath, encoding='utf-8')
            else:
                print("üìä [PDF] –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª...")
                df = pd.read_excel(filepath)
        except Exception as e:
            print(f"‚ö†Ô∏è [PDF] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å UTF-8, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è CSV
            if filename.endswith('.csv'):
                try:
                    print("üìä [PDF] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É cp1251...")
                    df = pd.read_csv(filepath, encoding='cp1251')
                except:
                    try:
                        print("üìä [PDF] –ü—Ä–æ–±—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É latin-1...")
                        df = pd.read_csv(filepath, encoding='latin-1')
                    except:
                        print(f"‚ùå [PDF] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                        return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
            else:
                print(f"‚ùå [PDF] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
                return jsonify({'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'}), 500
        
        print(f"üìà [PDF] –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("üßπ [PDF] –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        df = df.dropna(how='all')
        df = df.dropna(axis=1, how='all')
        df = df.where(pd.notnull(df), None)
        df = df.replace(['', ' ', '  ', '   '], None)  # –ó–∞–º–µ–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ None
        df = df.replace(['nan', 'NaN', 'NAN'], None)  # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ 'nan' –Ω–∞ None
        
        print(f"‚ú® [PDF] –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        print("üìä [PDF] –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É...")
        data_types = detect_data_types(df)
        analytics = get_basic_analytics(df)
        print(f"‚úÖ [PDF] –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –≥–æ—Ç–æ–≤–∞: {len(analytics)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è PDF
        df_sample = df.head(50)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —Å—Ç—Ä–æ–∫ –¥–ª—è PDF
        df_sample_clean = convert_dataframe_to_json_safe(df_sample)
        table_data = df_sample_clean.to_dict('records')
        print(f"üìã [PDF] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(table_data)} —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã –≤ PDF")
        
        # –ü–æ–ª—É—á–∞–µ–º AI –∞–Ω–∞–ª–∏–∑—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        ai_analyses = {}
        if yandex_analysis and yandex_analysis != '–ó–¥–µ—Å—å –ø–æ—è–≤–∏—Ç—Å—è –≤—ã–≤–æ–¥ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏':
            ai_analyses['yandex'] = yandex_analysis
            print(f"ü§ñ [PDF] –Ø–Ω–¥–µ–∫—Å.GPT –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á—ë–Ω –≤ PDF: {len(yandex_analysis)} —Å–∏–º–≤–æ–ª–æ–≤")
        if gigachat_analysis and gigachat_analysis != '–ó–¥–µ—Å—å –ø–æ—è–≤–∏—Ç—Å—è –≤—ã–≤–æ–¥ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏':
            ai_analyses['gigachat'] = gigachat_analysis
            print(f"ü§ñ [PDF] GigaChat –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á—ë–Ω –≤ PDF: {len(gigachat_analysis)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if not ai_analyses:
            print("ü§ñ [PDF] AI –∞–Ω–∞–ª–∏–∑—ã –Ω–µ –≤–∫–ª—é—á–µ–Ω—ã –≤ PDF")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è PDF –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        pdf_data = {
            'filename': filename,
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'columns': list(df.columns),
            'table_data': table_data,
            'analytics': analytics,
            'ai_analyses': ai_analyses
        }
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è PDF
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_filename = f"analytics_report_{timestamp}.pdf"
        pdf_path = os.path.join(app.config['UPLOAD_FOLDER'], pdf_filename)
        
        print(f"üìÑ [PDF] –°–æ–∑–¥–∞—ë–º PDF —Ñ–∞–π–ª: {pdf_filename}")
        print(f"üìÅ [PDF] –ü—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {pdf_path}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
        print("üîÑ [PDF] –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é PDF...")
        success = create_pdf_report(pdf_data, pdf_path)
        
        if success:
            file_size = os.path.getsize(pdf_path)
            print(f"‚úÖ [PDF] PDF –æ—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
            print(f"üìä [PDF] –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            print(f"üìÑ [PDF] –ò–º—è —Ñ–∞–π–ª–∞: {pdf_filename}")
            return jsonify({
                'success': True,
                'pdf_filename': pdf_filename,
                'message': 'PDF –æ—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω'
            })
        else:
            print("‚ùå [PDF] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF –æ—Ç—á—ë—Ç–∞")
            return jsonify({
                'success': False,
                'error': '–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF –æ—Ç—á–µ—Ç–∞'
            }), 500
        
    except Exception as e:
        print(f"‚ùå [PDF] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        print(f"üîç [PDF] –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF: {str(e)}'}), 500

@app.route('/download_pdf/<filename>')
def download_pdf(filename):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF —Ñ–∞–π–ª–∞"""
    try:
        print(f"üì• [DOWNLOAD] –ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ PDF: {filename}")
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        if os.path.exists(filepath):
            file_size = os.path.getsize(filepath)
            print(f"‚úÖ [DOWNLOAD] PDF —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω: {filepath}")
            print(f"üìä [DOWNLOAD] –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            print(f"üì§ [DOWNLOAD] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –∫–ª–∏–µ–Ω—Ç—É...")
            
            response = send_file(filepath, as_attachment=True, download_name=filename)
            print(f"‚úÖ [DOWNLOAD] –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∫–ª–∏–µ–Ω—Ç—É")
            return response
        else:
            print(f"‚ùå [DOWNLOAD] PDF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
            return jsonify({'error': 'PDF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404
    except Exception as e:
        print(f"‚ùå [DOWNLOAD] –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF: {str(e)}")
        import traceback
        print(f"üîç [DOWNLOAD] –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
        logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF: {e}")
        return jsonify({'error': f'–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {str(e)}'}), 500

if __name__ == '__main__':
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
    os.makedirs('templates', exist_ok=True)
    os.makedirs('static', exist_ok=True)
    os.makedirs('uploads', exist_ok=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—Ç –¥–ª—è Render
    port = int(os.environ.get('PORT', 5000))
    
    logger.info("–ó–∞–ø—É—Å–∫ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Excel/CSV/PDF —Ñ–∞–π–ª–æ–≤...")
    
    # –ó–∞–ø—É—Å–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if os.environ.get('RENDER'):
        # –ü—Ä–æ–¥–∞–∫—à–µ–Ω —Ä–µ–∂–∏–º –¥–ª—è Render
        app.run(host='0.0.0.0', port=port, debug=False)
    else:
        # –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
        app.run(debug=True, host='0.0.0.0', port=port)
